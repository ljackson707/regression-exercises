{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "\"Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\"\n",
    "Jason Brownlee, [Machine Learning Mastery](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "\n",
    "You can construct new features out of existing features, select features the best features, remove the worst features, penalize features by giving them no weight in the model, transform features, as examples. \n",
    "\n",
    "Some feature engineering methods include:  \n",
    "\n",
    "- Construct new features: Use domain knowledge, creating products of features, etc. \n",
    "\n",
    "- Use statistical tests to determine each feature's usefulness in predicting the target variable. Rank the features and then select the K best features (Select K Best). \n",
    "\n",
    "- Recursively remove attributes to meet the number of required features and then build a model on those attributes that remain to see if you can you match or improve performance with a smaller subset (Recursive Feature Elimination).   \n",
    "- Recursively remove the worst performing features one by one till the overall performance of the model comes in acceptable range (Backward Elimination).  \n",
    "\n",
    "- Add features one at a time beginning with the predictor with the highest correlation with the dependent variable. Variables of greater theoretical importance are entered first. Once in the equation, the variable remains there (Forward Selection). \n",
    "\n",
    "- many, many more...(see appendix for more such as PCA and regularization). \n",
    "\n",
    "**For the feature engineering methods with regression, we want to use the scaled data**\n",
    "\n",
    "## The Short Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import env\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test(df, target):\n",
    "    '''\n",
    "    this function takes in a dataframe and splits it into 3 samples, \n",
    "    a test, which is 20% of the entire dataframe, \n",
    "    a validate, which is 24% of the entire dataframe,\n",
    "    and a train, which is 56% of the entire dataframe. \n",
    "    It then splits each of the 3 samples into a dataframe with independent variables\n",
    "    and a series with the dependent, or target variable. \n",
    "    The function returns 3 dataframes and 3 series:\n",
    "    X_train (df) & y_train (series), X_validate & y_validate, X_test & y_test. \n",
    "    '''\n",
    "    # split df into test (20%) and train_validate (80%)\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "\n",
    "    # split train_validate off into train (70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "\n",
    "        \n",
    "    # split train into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "    \n",
    "    # split validate into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_validate = validate.drop(columns=[target])\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    # split test into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "def get_numeric_X_cols(X_train, object_cols):\n",
    "    '''\n",
    "    takes in a dataframe and list of object column names\n",
    "    and returns a list of all other columns names, the non-objects. \n",
    "    '''\n",
    "    numeric_cols = [col for col in X_train.columns.values if col not in object_cols]\n",
    "    \n",
    "    return numeric_cols\n",
    "\n",
    "\n",
    "def min_max_scale(X_train, X_validate, X_test, numeric_cols):\n",
    "    '''\n",
    "    this function takes in 3 dataframes with the same columns, \n",
    "    a list of numeric column names (because the scaler can only work with numeric columns),\n",
    "    and fits a min-max scaler to the first dataframe and transforms all\n",
    "    3 dataframes using that scaler. \n",
    "    it returns 3 dataframes with the same column names and scaled values. \n",
    "    '''\n",
    "    # create the scaler object and fit it to X_train (i.e. identify min and max)\n",
    "    # if copy = false, inplace row normalization happens and avoids a copy (if the input is already a numpy array).\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler(copy=True).fit(X_train[numeric_cols])\n",
    "\n",
    "    #scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train. \n",
    "    # \n",
    "    X_train_scaled_array = scaler.transform(X_train[numeric_cols])\n",
    "    X_validate_scaled_array = scaler.transform(X_validate[numeric_cols])\n",
    "    X_test_scaled_array = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, \n",
    "                                  columns=numeric_cols).\\\n",
    "                                  set_index([X_train.index.values])\n",
    "\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled_array, \n",
    "                                     columns=numeric_cols).\\\n",
    "                                     set_index([X_validate.index.values])\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, \n",
    "                                 columns=numeric_cols).\\\n",
    "                                 set_index([X_test.index.values])\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df, object_cols):\n",
    "    '''\n",
    "    This function takes in a dataframe and list of object column names,\n",
    "    and creates dummy variables of each of those columns. \n",
    "    It then appends the dummy variables to the original dataframe. \n",
    "    It returns the original df with the appended dummy variables. \n",
    "    '''\n",
    "    \n",
    "    # run pd.get_dummies() to create dummy vars for the object columns. \n",
    "    # we will drop the column representing the first unique value of each variable\n",
    "    # we will opt to not create na columns for each variable with missing values \n",
    "    # (all missing values have been removed.)\n",
    "    dummy_df = pd.get_dummies(object_cols, dummy_na=False, drop_first=True)\n",
    "    \n",
    "    # concatenate the dataframe with dummies to our original dataframe\n",
    "    # via column (axis=1)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_cols(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and identifies the columns that are object types\n",
    "    and returns a list of those column names. \n",
    "    '''\n",
    "    # create a mask of columns whether they are object type or not\n",
    "    mask = np.array(df.dtypes == \"object\")\n",
    "\n",
    "        \n",
    "    # get a list of the column names that are objects (from the mask)\n",
    "    object_cols = df.iloc[:, mask].columns.tolist()\n",
    "    \n",
    "    return object_cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_student_math(path):\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    \n",
    "    # drop any nulls\n",
    "    df = df[~df.isnull()]\n",
    "\n",
    "    # get object column names\n",
    "    object_cols = get_object_cols(df)\n",
    "    \n",
    "    # create dummy vars\n",
    "    df = create_dummies(df, object_cols)\n",
    "      \n",
    "    # split data \n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = train_validate_test(df, 'G3')\n",
    "    \n",
    "    # get numeric column names\n",
    "    numeric_cols = get_numeric_X_cols(X_train, object_cols)\n",
    "\n",
    "    # scale data \n",
    "    X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)\n",
    "    \n",
    "    return df, X_train, X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the source for the dataset and data dictionary https://archive.ics.uci.edu/ml/datasets/student+performance\n",
    "path = \"https://gist.githubusercontent.com/ryanorsinger/55ccfd2f7820af169baea5aad3a9c60d/raw/da6c5a33307ed7ee207bd119d3361062a1d1c07e/student-mat.csv\"\n",
    "\n",
    "df, X_train_explore, \\\n",
    "    X_train_scaled, y_train, \\\n",
    "    X_validate_scaled, y_validate, \\\n",
    "    X_test_scaled, y_test = wrangle_student_math(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_explore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any nulls\n",
    "X_train_explore = X_train_explore.dropna(axis=1)\n",
    "X_train_scaled = X_train_scaled.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "142     GP   F   15       U     GT3       T     4     4   teacher  services   \n",
       "326     GP   M   17       U     GT3       T     3     3     other  services   \n",
       "88      GP   M   16       U     GT3       T     2     2  services     other   \n",
       "118     GP   M   17       R     GT3       T     1     3     other     other   \n",
       "312     GP   M   19       U     GT3       T     1     2     other  services   \n",
       "\n",
       "     ... romantic famrel  freetime  goout  Dalc Walc health absences  G1  G2  \n",
       "142  ...       no      4         2      2     1    1      5        2   9  11  \n",
       "326  ...       no      4         3      5     3    5      5        3  14  15  \n",
       "88   ...       no      4         4      2     1    1      3       12  11  10  \n",
       "118  ...       no      5         2      4     1    4      5       20   9   7  \n",
       "312  ...       no      4         5      2     2    2      4        3  13  11  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_explore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest\n",
    "\n",
    "Select the K best features using a statistical test to compare each X with y and find which X's have the strongest relationship with y. For regression, we will use the correlation test (`f-regression`) to score the relationships. \n",
    "\n",
    "1. Initialize the f_selector object, setting the parameters, or instructions for the method to follow: \"use the *f_regression* test for scoring the features, and return to me the top *10* features\", for example. \n",
    "2. Fit the object to our data. That is, run a correlation test for every X variable with our y variable, and then rank the X variables based on how correlated they are with the y/target variable. Then give me the top *10* features. \n",
    "3. Use get_support() to get the list of features, and save them to a variable that you can use to filter your dataframe in modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'Dalc',\n",
       " 'Walc',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# parameters: f_regression stats test, give me 8 features\n",
    "f_selector = SelectKBest(f_regression, k=14)\n",
    "\n",
    "# find the top 8 X's correlated with y\n",
    "f_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# boolean mask of whether the column was selected or not. \n",
    "feature_mask = f_selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boolean mask is a name for an array of booleans\n",
    "feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of top K features. \n",
    "f_feature = X_train_scaled.iloc[:,feature_mask].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'Walc',\n",
       " 'health',\n",
       " 'absences',\n",
       " 'G1',\n",
       " 'G2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we know\n",
    "- k of 1 says G2 (midterm)\n",
    "- k of 2 says G1 and G2 midterm\n",
    "- k of 3 says failures, G1 and G2\n",
    "- k4 adds Maternal educational background\n",
    "- k5 is ['Medu', 'Fedu', 'failures', 'G1', 'G2']\n",
    "- k6 is ['age', 'Medu', 'Fedu', 'failures', 'G1', 'G2']\n",
    "- k7 is ['age', 'Medu', 'Fedu', 'traveltime', 'failures', 'G1', 'G2']\n",
    "- k8 is ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'G1', 'G2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "Recursive Feature Elimination will create a model with all the features, evaluate the performance metrics, find the weakest feature, remove it, then create a new model with the remaining features, evaluate the performance metrics, find the weakest feature, remove it, and so on, until it gets down to the number of features you have indicated you want when creating the rfe object. You will also indicate which Machine Learning algorithm you want to use. \n",
    "\n",
    "1. Initialize the machine learning algorithm, in this case LinearRegression\n",
    "2. Initialize the RFE object, and provide the ML algorithm object from step 1\n",
    "3. Fit the RFE object to our data. Doing this will provide us a list of features (the number we asked for) as well as a ranking of all the features. \n",
    "4. Assign the list of selected features to a variable. \n",
    "5. Optional: Get ranking of all variables (1 being most important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='G2', ylabel='G3'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's make sure there's a linear relationship between the feature(s) and the target\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x=\"G2\", y=y_train, data=X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# initialize the ML algorithm\n",
    "lm = LinearRegression()\n",
    "\n",
    "# create the rfe object, indicating the ML object (lm) and the number of features I want to end up with. \n",
    "rfe = RFE(lm, 2)\n",
    "\n",
    "# fit the data using RFE\n",
    "rfe.fit(X_train_scaled,y_train)  \n",
    "\n",
    "# get the mask of the columns selected\n",
    "feature_mask = rfe.support_\n",
    "\n",
    "# get list of the column names. \n",
    "rfe_feature = X_train_scaled.iloc[:,feature_mask].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G1', 'G2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>absences</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>famrel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traveltime</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>health</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>failures</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medu</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dalc</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>goout</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walc</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fedu</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>freetime</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>studytime</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var  Rank\n",
       "13          G1     1\n",
       "14          G2     1\n",
       "12    absences     2\n",
       "0          age     3\n",
       "6       famrel     4\n",
       "3   traveltime     5\n",
       "11      health     6\n",
       "5     failures     7\n",
       "1         Medu     8\n",
       "9         Dalc     9\n",
       "8        goout    10\n",
       "10        Walc    11\n",
       "2         Fedu    12\n",
       "7     freetime    13\n",
       "4    studytime    14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view list of columns and their ranking\n",
    "\n",
    "# get the ranks\n",
    "var_ranks = rfe.ranking_\n",
    "\n",
    "# get the variable names\n",
    "var_names = X_train_scaled.columns.tolist()\n",
    "\n",
    "# combine ranks and names into a df for clean viewing\n",
    "rfe_ranks_df = pd.DataFrame({'Var': var_names, 'Rank': var_ranks})\n",
    "\n",
    "# sort the df by rank\n",
    "rfe_ranks_df.sort_values('Rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Longer Lesson \n",
    "\n",
    "This part of the lesson goes through what we just covered above, but with more depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best \n",
    "\n",
    "The goal of filter methods, such as SelectKBest, is to keep the attributes with highest correlation to the target variable and of those features, if two are highly correlated with each other, remove one of them. With filter methods, the model is built after selecting the features. These methods identify the relevant features and subset the data with only those features. \n",
    "\n",
    "Select K Best is a filter method, meaning the goal is to find and keep the attributes with highest correlation to the target variable and of those features, if two are highly correlated with each other, remove one of them. \n",
    "\n",
    "`SelectKBest` will identify the K most relevant features and subset the data with only those features. Relevancy is determined by the the test statistic for the chosen function or test (Chi-squared, F-regression, etc.). For regression, we will use the f-regression test to score the individual effect of each of the features (aka regressors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the f_selector object, setting the parameters, or instructions for the method to follow: \"use the f_regression test for scoring the features, and return to me the top 10 features\", for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_selector = SelectKBest(f_regression, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the object to our data. In doing this, our selector is scoring, ranking, and identifying the top `k` features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=2, score_func=<function f_regression at 0x12276fe18>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_selector.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Transform our dataset to reduce to the `k` best features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 15)\n",
      "(221, 2)\n"
     ]
    }
   ],
   "source": [
    "X_reduced = f_selector.transform(X_train_scaled)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify steps 1-3 in the following way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 2)\n"
     ]
    }
   ],
   "source": [
    "X_reduced2 = SelectKBest(f_regression, k=2).fit_transform(X_train_scaled, y_train)\n",
    "print(X_reduced2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `inverse_transform` function to return to the original variables. \n",
    "\n",
    "Let's say we want a list of the features we have selected. Why? Maybe we want to run various feature selection methods and want to keep track of how many times each feature was selected. We could simply grab the column names from our new dataframe above that contains only the best 2 features. However, maybe we don't need the new dataframe yet, as we aren't quite sure which features we will finally decide to keep. In that case, we would create the object using `SelectKBest`, `fit` it to the data (not transform), and then we could use `get_support` to get a mask, or integer index, of the features the algorithm selected. \n",
    "\n",
    "Let's walk through that. \n",
    "You will see below we end up with a list of booleans that relate to the feature indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False  True  True]\n"
     ]
    }
   ],
   "source": [
    "f_support = f_selector.get_support()\n",
    "\n",
    "print(f_support) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a list of the feature names selected from X_train using `.loc` with our mask, using `.columns` to get the column names, and convert the values to a list using `.tolist()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 selected features\n",
      "['G1', 'G2']\n"
     ]
    }
   ],
   "source": [
    "f_feature = X_train_scaled.loc[:,f_support].columns.tolist()\n",
    "\n",
    "# you could also get the list this way (among many others)\n",
    "# f_feature = [X_train_scaled.columns.values[i] for i in range(len(feature_mask)) if feature_mask[i]==True]\n",
    "\n",
    "print(str(len(f_feature)), 'selected features')\n",
    "print(f_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, we used the `SelectKBest` method to select the top `k` features, and these features are scored and ranked using a statistical test, which we used the f-regression test in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "Recursive Feature Elimination is a wrapper method for feature selection. This means that it works by using the output of a machine learning algorithm as the evaluation criteria for eliminating features; in the case of linear regression, it uses the resulting coefficients.\n",
    "\n",
    "You feed all the features to the selected Machine Learning algorithm, and, based on the the hyperparameters you have set, features are removed. One word of caution...this is an iterative and computationally expensive process! The pro is that it is more accurate than SelectKBest. \n",
    "\n",
    "RFE recursively removes attributes and then builds a model on those attributes that remain. The RFE method takes the machine learning algorithm to be used and the number of required features as input. It returns the ranking of all the variables, 1 being most important, along with its support: a list of boolean values, True indicating relevant features and False indicating irrelevant features.\n",
    "\n",
    "These are the steps we will take to implement RFE:  \n",
    "\n",
    "1. Initialize the linear regression object. `sklearn.linear_model.LinearRegression`  \n",
    "2. Initialize the RFE object. `sklearn.feature_selection.RFE`  \n",
    "3. Fit the RFE object to our data. `rfe.fit()`  \n",
    "4. Transform our X dataframe to include only those 2 features. `rfe.transform()`  \n",
    "5. Optional: Get list of features selected  \n",
    "6. Optional: Get ranking of all variables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the linear regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initialize the RFE object, setting the hyperparameters to be our linear regression object created above (as the algorithm to test the features on) and the number of features to return to be 2.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(lm, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the RFE object to our data. This means create multiple linear regression models, find the one that performs best, and identify the features that are used in that model. Those are the features we want.   \n",
    "4. Transform our X dataframe to include only those 2 features. `.transform()` *or do both of those steps together with `.fit_transform()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X_train_scaled,y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we move on to modeling, we would then use our new X dataframe as the one to move forward for actual modeling. As a sneak peak..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to model\n",
    "lm.fit(X_rfe,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. If we want a list of the features that remain, we can use `.support_` similar to how we used `.get_support()` with `SelectKBest`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_features = X_train_scaled.loc[:,mask].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 selected features\n",
      "['G1', 'G2']\n"
     ]
    }
   ],
   "source": [
    "print(str(len(rfe_features)), 'selected features')\n",
    "print(rfe_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. We can also get a ranking of the features using `rfe.ranking_`. This will return a 1 for the features that were selected. So, since we said we wanted 2 features to remain, the top two features will have a rank of 1. The features that were eliminated will be ranked accordingly. In this case, the third feature will have a rank of 2. However, if we had more than 1 feature that was eliminated, they would all have different ranks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medu</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fedu</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traveltime</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>studytime</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>failures</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>famrel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>freetime</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>goout</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dalc</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walc</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>health</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>absences</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Var  Rank\n",
       "0          age     3\n",
       "1         Medu     8\n",
       "2         Fedu    12\n",
       "3   traveltime     5\n",
       "4    studytime    14\n",
       "5     failures     7\n",
       "6       famrel     4\n",
       "7     freetime    13\n",
       "8        goout    10\n",
       "9         Dalc     9\n",
       "10        Walc    11\n",
       "11      health     6\n",
       "12    absences     2\n",
       "13          G1     1\n",
       "14          G2     1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ranks = rfe.ranking_\n",
    "var_names = X_train_scaled.columns.tolist()\n",
    "\n",
    "pd.DataFrame({'Var': var_names, 'Rank': var_ranks})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we took LinearRegression model with 2 features and RFE gave feature ranking as above, but the selection of number â€˜2â€™ was random. If you would like to learn how to find the optimum number of features, for which the accuracy is the highest, see the extended lesson in the appendix of ds.codeup.com.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We used SelectKBest to select the top 2 features based on how correlated each feature is with the target variable. We ended up with exam1 and exam3.    \n",
    "- We use RFE and a linear regression algorithm to keep the top 2 features based on which features lead to the best performing linear regression model. This eliminated exam2 and also left us with exam1 and exam3, like SelectKBest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
